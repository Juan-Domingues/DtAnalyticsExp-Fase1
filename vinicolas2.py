# -*- coding: utf-8 -*-
"""Vinicolas2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ff-QsAijvaZlGA-kdphm6E8t1iw6vLWb
"""

pip install requests pandas lxml html5lib openpyxl

import requests  # Para fazer as requisições HTTP
import pandas as pd # Para trabalhar com tabelas (DataFrames) e extrair tabelas HTML
import time      # Para adicionar pausas e ser gentil com o servidor

# Lista para armazenar os DataFrames de cada ano
todos_os_dados = []

# Definir o intervalo de anos
ano_inicio = 2010
ano_fim = 2024 # Dados até 2024

# Construir a base da URL
url_base = "http://vitibrasil.cnpuv.embrapa.br/index.php?opcao=opt_02&ano="

print(f"Iniciando a coleta de dados de {ano_inicio} a {ano_fim}...")

# Loop pelos anos desejados
for ano in range(ano_inicio, ano_fim + 1):
    # Construir a URL completa para o ano atual
    url_ano = url_base + str(ano)
    print(f"Buscando dados para o ano: {ano} - URL: {url_ano}")

    try:
        # --- Início da Lógica de Scraping (você precisa implementar/adaptar) ---

        # 1. Fazer a requisição para obter o conteúdo HTML da página
        #    É importante incluir headers para simular um navegador, se necessário.
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
        response = requests.get(url_ano, headers=headers, timeout=30) # Timeout de 30 segundos
        response.raise_for_status() # Verifica se a requisição foi bem sucedida (código 200)

        # 2. Usar Pandas para tentar extrair as tabelas diretamente do HTML
        #    pd.read_html é poderoso para isso. Ele retorna uma LISTA de DataFrames.
        #    Você precisará inspecionar a página para saber qual tabela na lista é a correta.
        #    Pode ser a primeira (índice 0), a segunda (índice 1), etc.
        lista_de_tabelas = pd.read_html(response.content, encoding='utf-8') # Tente utf-8 ou latin-1 se der erro

        # Exemplo: Supondo que a tabela de exportação seja a primeira encontrada
        if lista_de_tabelas:
             # Seleciona a tabela correta (você precisa verificar qual é - talvez a primeira, segunda etc.)
             # Exemplo: vamos supor que seja a primeira tabela com cabeçalho "Países"
             df_exportacao_ano = None
             for tabela in lista_de_tabelas:
                 # Verifique se a primeira coluna (ou alguma coluna específica) tem o nome esperado
                 if 'Países' in tabela.columns: # Ajuste 'Países' se o nome for outro
                     df_exportacao_ano = tabela
                     break # Sai do loop assim que encontrar a tabela correta

             if df_exportacao_ano is not None:
                # 3. Adicionar uma coluna com o ano para identificar a origem dos dados
                df_exportacao_ano['Ano'] = ano

                # 4. Limpeza de Dados (Opcional, mas geralmente necessário)
                #    Remover linhas de total, converter tipos de dados (ex: número para float), etc.
                #    Exemplo: Remover linha de total (ajuste conforme o nome exato)
                # df_exportacao_ano = df_exportacao_ano[df_exportacao_ano['Países'] != 'TOTAL']
                #    Exemplo: Converter colunas de quantidade/valor para numérico (removendo pontos e trocando vírgula)
                # for col in ['Quantidade (Kg)', 'Valor (US$)']: # Ajuste os nomes das colunas
                #     if col in df_exportacao_ano.columns:
                #         df_exportacao_ano[col] = df_exportacao_ano[col].astype(str).str.replace('.', '', regex=False).str.replace(',', '.', regex=False)
                #         df_exportacao_ano[col] = pd.to_numeric(df_exportacao_ano[col], errors='coerce')

                # 5. Adicionar o DataFrame do ano à lista geral
                todos_os_dados.append(df_exportacao_ano)
                print(f"Dados de {ano} extraídos com sucesso.")
             else:
                 print(f"AVISO: Tabela de exportação não encontrada para o ano {ano} no formato esperado.")
        else:
            print(f"AVISO: Nenhuma tabela encontrada na página para o ano {ano}.")

        # --- Fim da Lógica de Scraping ---

    except requests.exceptions.RequestException as e:
        print(f"ERRO ao acessar a URL para o ano {ano}: {e}")
    except ImportError:
        print("ERRO: Bibliotecas necessárias (requests, pandas, lxml/html5lib) não instaladas.")
        print("Instale com: pip install requests pandas lxml html5lib")
        break
    except Exception as e:
        print(f"ERRO inesperado ao processar o ano {ano}: {e}")

    # Pausa educada para não sobrecarregar o servidor
    time.sleep(2) # Espera 2 segundos entre as requisições

# Verificar se algum dado foi coletado
if todos_os_dados:
    # Concatenar todos os DataFrames anuais em um único DataFrame
    df_final_exportacao = pd.concat(todos_os_dados, ignore_index=True)

    # Exibir as primeiras linhas do DataFrame final
    print("\n--- Dados Consolidados (Primeiras Linhas) ---")
    print(df_final_exportacao.head())

    # Exibir as últimas linhas do DataFrame final
    print("\n--- Dados Consolidados (Últimas Linhas) ---")
    print(df_final_exportacao.tail())

    # Salvar os dados consolidados em um arquivo CSV ou Excel
    try:
        df_final_exportacao.to_csv("exportacao_vinhos_vitibrasil_2010-2024.csv", index=False, sep=';', encoding='utf-8-sig')
        # ou para Excel:
        # df_final_exportacao.to_excel("exportacao_vinhos_vitibrasil_2010-2024.xlsx", index=False)
        print("\nDados salvos com sucesso em 'exportacao_vinhos_vitibrasil_2010-2024.csv'")
    except Exception as e:
        print(f"\nERRO ao salvar o arquivo: {e}")
else:
    print("\nNenhum dado foi coletado.")

import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import pandas as pd
import time
import logging
import re # Import regular expressions for cleaning

# Configuração básica de logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- Configuração de Retentativas ---
def create_session_with_retries():
    session = requests.Session()
    # Define a estratégia de retentativas:
    # total=5: Tentar até 5 vezes no total (1 inicial + 4 retentativas)
    # backoff_factor=1: Esperar 1s, 2s, 4s, 8s entre as tentativas
    # status_forcelist=[500, 502, 503, 504]: Tentar novamente para erros de servidor
    # allowed_methods=None: Tenta para todos os métodos (incluindo GET)
    # Adicionado connect=5 para retentar em erros de conexão como 'Connection refused'
    retries = Retry(total=5,
                    backoff_factor=1,
                    status_forcelist=[500, 502, 503, 504],
                    connect=5, # Retenta em erros de conexão
                    allowed_methods=None) # Use False se quiser retentar apenas em métodos idempotentes
    # Monta o adaptador com a estratégia de retentativas para HTTP e HTTPS
    session.mount('http://', HTTPAdapter(max_retries=retries))
    session.mount('https://', HTTPAdapter(max_retries=retries))
    return session
# --- Fim da Configuração de Retentativas ---

# Lista para armazenar os DataFrames de cada ano
todos_os_dados = []

# Definir o intervalo de anos
ano_inicio = 2010
ano_fim = 2023

# Construir a base da URL (opcao=opt_02 é para Produção, como na imagem)
url_base = "http://vitibrasil.cnpuv.embrapa.br/index.php?opcao=opt_02&ano="

# Mensagem inicial indicando o período de coleta.
logging.info(f"Iniciando a coleta de dados de PRODUÇÃO de {ano_inicio} a {ano_fim}...")

# Cria a sessão com retentativas
session = create_session_with_retries()

# Loop pelos anos desejados
for ano in range(ano_inicio, ano_fim + 1):
    url_ano = url_base + str(ano)
    logging.info(f"Buscando dados para o ano: {ano} - URL: {url_ano}")

    try:
        # 1. Fazer a requisição usando a sessão com retentativas
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
        response = session.get(url_ano, headers=headers, timeout=30) # Usar a sessão
        response.raise_for_status() # Verifica erros HTTP (4xx, 5xx) após as retentativas
        response.encoding = response.apparent_encoding if response.apparent_encoding else 'latin-1'

        # 2. Usar Pandas para extrair a tabela de Produção
        # Tenta encontrar a tabela que contenha "Produto" no cabeçalho ou no corpo
        try:
             # Usar 'Produto' como critério para encontrar a tabela correta
            lista_de_tabelas = pd.read_html(response.text, flavor='lxml', match='Produto')
            logging.info(f"Encontrada(s) {len(lista_de_tabelas)} tabela(s) com 'Produto' para o ano {ano}.")
        except ValueError:
            logging.warning(f"Não foi possível encontrar tabela com 'match=Produto' para o ano {ano}. Verificando todas as tabelas.")
            # Se match falhar, ler todas e procurar manualmente (menos eficiente)
            lista_de_tabelas = pd.read_html(response.text, flavor='lxml')


        if lista_de_tabelas:
            df_producao_ano = None
            # Itera para encontrar a tabela correta (geralmente a primeira com 'Produto')
            for tabela in lista_de_tabelas:
                if isinstance(tabela, pd.DataFrame) and 'Produto' in tabela.columns:
                    # Renomeia colunas para simplificar (remove parênteses, etc.)
                    tabela.columns = ['Produto', 'Quantidade_L'] # Nomes mais simples
                    df_producao_ano = tabela
                    logging.info(f"Tabela de Produção encontrada e colunas renomeadas para o ano {ano}.")
                    break

            if df_producao_ano is not None:
                # 3. Adicionar coluna Ano
                df_producao_ano['Ano'] = ano

                # 4. Filtrar pelos Produtos desejados
                # Manter linhas que contenham "VINHO DE MESA" ou "VINHO FINO DE MESA"
                # Usamos str.contains com regex '|' (OR), case=False para ignorar maiúsc./minúsc.
                # Precisamos tratar NaNs na coluna Produto antes de usar .str
                df_producao_ano_filtrado = df_producao_ano[
                    df_producao_ano['Produto'].astype(str).str.contains(
                        'VINHO DE MESA|VINHO FINO DE MESA',
                        case=False, na=False, regex=True
                    )
                ].copy() # Usar .copy() para evitar SettingWithCopyWarning

                logging.info(f"Dados filtrados para Vinho de Mesa/Vinho Fino. {len(df_producao_ano_filtrado)} linhas mantidas.")

                if not df_producao_ano_filtrado.empty:
                    # 5. Limpeza da Coluna de Quantidade
                    col_quant = 'Quantidade_L'
                    if col_quant in df_producao_ano_filtrado.columns:
                        logging.debug(f"Limpando coluna numérica: {col_quant}")
                        # Garante que é string, remove pontos, troca vírgula, remove não-numéricos (exceto .)
                        df_producao_ano_filtrado[col_quant] = df_producao_ano_filtrado[col_quant].astype(str)
                        df_producao_ano_filtrado[col_quant] = df_producao_ano_filtrado[col_quant].str.replace('.', '', regex=False)
                        # Removido troca de vírgula, pois os números na imagem usam ponto como separador de milhar
                        # df_producao_ano_filtrado[col_quant] = df_producao_ano_filtrado[col_quant].str.replace(',', '.', regex=False)
                        df_producao_ano_filtrado[col_quant] = df_producao_ano_filtrado[col_quant].str.replace(r'[^\d]', '', regex=True) # Remove tudo que não for dígito

                        # Converte para numérico, tratando erros
                        df_producao_ano_filtrado[col_quant] = pd.to_numeric(df_producao_ano_filtrado[col_quant], errors='coerce')
                        df_producao_ano_filtrado[col_quant] = df_producao_ano_filtrado[col_quant].fillna(0).astype(int) # Preenche NaN com 0 e converte para inteiro
                        logging.debug(f"Coluna {col_quant} limpa e convertida para inteiro.")
                    else:
                         logging.warning(f"Coluna '{col_quant}' não encontrada para limpeza no ano {ano}.")


                    # 6. Adicionar o DataFrame filtrado e limpo à lista geral
                    todos_os_dados.append(df_producao_ano_filtrado)
                    logging.info(f"Dados de Produção (filtrados) de {ano} extraídos e limpos com sucesso.")
                else:
                    logging.warning(f"Nenhum dado de Vinho de Mesa/Fino encontrado para o ano {ano} após filtragem.")

            else:
                logging.warning(f"Tabela de Produção ('Produto') não encontrada para o ano {ano} após ler o HTML.")
        else:
            logging.warning(f"Nenhuma tabela encontrada na página para o ano {ano}.")

    except requests.exceptions.RequestException as e:
        # Erros de conexão/timeout/HTTP após retentativas
        logging.error(f"ERRO FINAL ao acessar/processar URL para o ano {ano} após retentativas: {e}")
    except ImportError:
        logging.error("ERRO: Biblioteca 'lxml' não instalada. Instale com: pip install lxml")
        break
    except Exception as e:
        logging.error(f"ERRO inesperado ao processar o ano {ano}: {e}", exc_info=True)

    # Pausa educada entre as requisições
    logging.debug("Pausa de 2 segundos...")
    time.sleep(2)

# --- Fim do Loop ---

# Verificar se algum dado foi coletado
if todos_os_dados:
    logging.info("Concatenando os dados de todos os anos...")
    df_final_producao = pd.concat(todos_os_dados, ignore_index=True)

    logging.info("\n--- Dados Consolidados Finais (Primeiras Linhas) ---\n" + df_final_producao.head().to_string())
    logging.info("\n--- Dados Consolidados Finais (Últimas Linhas) ---\n" + df_final_producao.tail().to_string())
    logging.info(f"\n--- Informações do DataFrame Final ---")
    df_final_producao.info()

    # Salvar os dados consolidados em um arquivo CSV
    output_filename = f"producao_vinhos_vitibrasil_{ano_inicio}-{ano_fim}.csv"
    try:
        df_final_producao.to_csv(output_filename, index=False, sep=';', encoding='utf-8-sig')
        logging.info(f"Dados salvos com sucesso em '{output_filename}'")
    except Exception as e:
        logging.error(f"ERRO ao salvar o arquivo '{output_filename}': {e}")
else:
    logging.warning("Nenhum dado de produção de vinho foi coletado com sucesso.")

logging.info("Processo de coleta de dados finalizado.")

!python coletar_producao.py

python coletar_producao.py